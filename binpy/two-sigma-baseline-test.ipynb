{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ffb21374c7cf4b98e7239045ef9bf312effee25"
   },
   "source": [
    "# Two Sigma News Baseline Test\n",
    "\n",
    "TO DO:<br>\n",
    "Do I use rows universe==0 ?  there are no PrevMktres values for these, but there is a NextMkres10 (so that can be put in PrevMkres10) !<br>\n",
    "Check news_sample is not losing news items from news_train_df<br>\n",
    "\n",
    "\n",
    "This Kernel goes through the bare minimum to produce a result. The sections are as follows.\n",
    "\n",
    "* **Initialisation** Import and read the data. Define generic functions.<br>\n",
    "* **Training Data - Market** Choose Market columns plus example<br>\n",
    "* **Training Data - News** Choose News columns plus example<br>\n",
    "* **Training Data - Merging Market with News** Merge procedure and test<br>\n",
    "* **Training Data - Preparation** Sort by date and asset. Split into train and validation data<br>\n",
    "* **Neural Net** Use LightGBM and do some checks of train and validation data<br>\n",
    "* **Test data** Iterate through the test data and make predictions<br>\n",
    "* **Submission** Write the submission file and instructions on how to use it as the competition entry<br>\n",
    "* **Final word regarding the need to restart the kernel**<br>\n",
    "\n",
    "#### Results (not great)\n",
    "* Predictions using model: an RMSE score of: `0.06457`\n",
    "* Predictionsusing model: a Kaggle Leaderboard score of: `-0.16318`\n",
    "* All zero predictions: an RMSE score of: `0.06466` (only a tiny bit worse than the predictions)\n",
    "* All zero predictions: a Kaggle Leaderboard score of: `0.0`\n",
    "* Random predictions: an RMSE score of: `0.5807` (way worse then the predictions)\n",
    "* Random predictions: a Kaggle Leaderboard score of: `-0.05323`\n",
    "\n",
    "#### The Data<br>\n",
    "<p align=\"left\"> Data | <p align=\"left\"> Dataframe|<p align=\"left\"> Period\n",
    "---|:---|:---\n",
    "<p align=\"left\"> market train data | <p align=\"left\"> (4072956, 16) | <p align=\"left\"> 1/2/2007 - 30/12/2016\n",
    "<p align=\"left\"> news train data | <p align=\"left\"> (9328750, 35)**&ast;** | <p align=\"left\"> 1/1/2007 - 30/12/2016\n",
    "<p align=\"left\"> market test data | <p align=\"left\"> (&lt;assets per day>, 14)**&ast;&ast;** | <p align=\"left\"> 3/1/2017 - 15/7/2019\n",
    "<p align=\"left\"> news test data | <p align=\"left\"> (&lt;news items per day>, 35)**&ast;** | <p align=\"left\"> 30/12/2016 - 14/7/2019\n",
    "\n",
    "**&ast; news is rated for relevance, good, bad etc. how reliable is this?**<br>\n",
    "**&ast;&ast; test data is given day by day, also without fields `universe` and `returnsOpenNextMktres10`**\n",
    "\n",
    "#### Notes<br>\n",
    "**universe==0** there are a lot of these and although there is no PrevMkres data the rest is there, including NextMkres10<br>\n",
    "**Market returns** = ((close price – open price) / open price)   (ie. raw+unadjusted; eg. 120-100/100 = 0.2 = 20% return)<br>\n",
    "**Market residualised returns** = market returns - benchmark returns; plus taking splits/dividents into account<br>\n",
    "**Benchmark Market returns** = *how do I get this?*<br>\n",
    "**`meanReturnsMkres1` and `meanReturnsMkres10`** would these new values be useful?<br>\n",
    "**`returnsOpenPrevRaw10 - returnsOpenPrevMkres10`** will be benchmark return rate plus split/dividend calculation<br>\n",
    "**`returnsOpenLastMktres10` and `returnsOpenNextMktres10`** should be the same 10 trading days apart<br>\n",
    "**Output is `assetCode,confidenceValue`** (ie. predicting: `returnsOpenNextMktres10`); range [-1,1], 0 = least confidence<br>\n",
    "**News data** *is it worth defining an algorithm to consolidate multiple news items for one stock on one day?*<br>\n",
    "**`firstMentionSentence`** needs to be 0, 1 or 2 in order to trust the `sentimentNegative/Neutral/Positive` probabilities\n",
    "\n",
    "#### Timeline<br>\n",
    "25/09/2018: start<br>\n",
    "02/01/2019:\tteam merger deadline<br>\n",
    "08/01/2019:\tsubmission deadline (select two best submissions to be rescored)<br>\n",
    "15/07/2019:\tend\n",
    "\n",
    "\n",
    "#### End to end usage example from Two Sigma<br>\n",
    "The training data can be read in one go (4 million and 9 million lines for market and news data respectively).<br>\n",
    "You can only read in a day's worth of test data: ie. read, predict, read, predict, etc. 639 times for the 639 days of test data.<br>\n",
    "*NOTE: create the functions `train_my_model` and `make_my_predictions` and uncomment all the three commented lines.*\n",
    "```python\n",
    "from kaggle.competitions import twosigmanews\n",
    "env = twosigmanews.make_env()\n",
    "(market_train_df, news_train_df) = env.get_training_data()\n",
    "#train_my_model(market_train_df, news_train_df)\n",
    "i = 0\n",
    "for (market_test_df, news_test_df, predictions_template_df) in env.get_prediction_days():\n",
    "    predictions_df = predictions_template_df\n",
    "    #predictions_df = make_my_predictions(market_test_df, news_test_df, predictions_template_df)\n",
    "    env.predict(predictions_df)\n",
    "    i = i + 1\n",
    "print (i)\n",
    "#env.write_submission_file()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "225708f447eee93041881f9d6c3a3e890cb16718"
   },
   "source": [
    "# Initialisation\n",
    "* Usual imports\n",
    "* Set up the training data frames (save memory if you don't want submit test predictions)\n",
    "* Define generic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/lightgbm/__init__.py:45: FutureWarning:\n",
      "\n",
      "Starting from version 2.2.1, the library file in distribution wheels for macOS will be built by the Apple Clang compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you won't need to install the gcc compiler anymore.\n",
      "Instead of that, you'll need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import lightgbm as lgb\n",
    "from itertools import chain\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "orig_max_rows = pd.options.display.max_rows\n",
    "#pd.set_option('display.max_rows', 100000)\n",
    "#pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "submit_test = False  # keep / delete the env object (ie. training only)\n",
    "use_news = True      # use / don't use news for training\n",
    "\n",
    "market_train_df = pd.read_csv(\"../input/two-sigma-financial-news/marketdata.csv\")\n",
    "news_train_df   = pd.read_csv(\"../input/two-sigma-financial-news/newsdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only for running from Kaggle:\n",
    "#from kaggle.competitions import twosigmanews\n",
    "#env = twosigmanews.make_env()\n",
    "#(market_train_df, news_train_df) = env.get_training_data()\n",
    "#if submit_test is False:\n",
    "#    print (\"Not submitting test with this run so removing 'env' class to free memory\")\n",
    "#    del env\n",
    "#    gc.collect()\n",
    "# MEMORY CHECK: env uses 4.5 GB;  total: 5 GB (briefly hits 9GB though)\n",
    "# MEMORY CHECK: dfs use: 2.8 GB;  total: 7.8 GB\n",
    "# MEMORY CHECK: if submit_test is False: 5 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "c21b3203a30537da859b931485366d3f9ba84117"
   },
   "outputs": [],
   "source": [
    "def summary(df, cols=None):\n",
    "    if cols == None:\n",
    "        cols = df.columns\n",
    "    nrows = df.shape[0]\n",
    "    if (nrows > orig_max_rows):\n",
    "        pd.set_option('display.max_rows', nrows)\n",
    "    print('DataFrame shape',df.shape)\n",
    "    sdf = pd.DataFrame(index=cols, columns=['Null','dType','Type','Unique','Examples'])\n",
    "    for col in cols:\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "        sdf['Null'][col]     = df[col].isna().sum()\n",
    "        sdf['Unique'][col]   = len(list(df[col].unique()))\n",
    "        sdf['dType'][col]    = df[col].dtypes\n",
    "        sdf['Type'][col]     = \"-\" if df[col].notna().sum() == 0 else type(df[col].dropna().iloc[0])\n",
    "        sdf['Examples'][col] = \"-\" if df[col].notna().sum() == 0 else list(df[col].unique())\n",
    "    return sdf.fillna('-')\n",
    "\n",
    "# return (1) everything; (2) rows where 'time' == datefrom or (3) rows within a date range\n",
    "def get_dates(df, datefrom=None, dateto=None):\n",
    "    if datefrom is None:\n",
    "        return (df['time'] != None)\n",
    "    elif dateto is None:\n",
    "        return (df['time'] == datefrom)\n",
    "    else:\n",
    "        return ((df['time'] >= datefrom) & (df['time'] <= dateto))\n",
    "\n",
    "def df_memoryMB(df):\n",
    "    return df.memory_usage().sum() / (1024 * 1024)\n",
    "\n",
    "# Recursively finds size of objects\n",
    "def get_class_size(obj, seen=None):\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Mark as \"seen\" before entering recursion to cater for self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_class_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_class_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_class_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_class_size(i, seen) for i in obj])\n",
    "    return size\n",
    "\n",
    "# get rough'n'ready memory calculation for class\n",
    "def class_memoryMB(obj):\n",
    "    return get_class_size(obj) / (1024 * 1024)\n",
    "\n",
    "def show_year_rows_before_time_conversion(marketdf, newsdf):\n",
    "    def show_year_rows(df, dfname):\n",
    "        yearlist = df['time'].dt.year.tolist()\n",
    "        print (\"{:s} train rows for each year:\".format(dfname))\n",
    "        for year in sorted(set(yearlist)):\n",
    "            print (\"{:d}: {:d}\".format(year, yearlist.count(year)))\n",
    "    show_year_rows(marketdf, \"market\")\n",
    "    show_year_rows(newsdf,   \"news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "f5da6e01261d34ed189654dc80b7edcbc0d23456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market train dates: 20100104 to 20161230\n",
      "news   train dates: 20100101 to 20161230\n",
      "market train shape: (2946739, 17)\n",
      "news   train shape: (7003400, 36)\n",
      "market train memory (MB): 382.1912612915039\n",
      "news   train memory (MB): 1876.7885971069336\n"
     ]
    }
   ],
   "source": [
    "# converted time already\n",
    "market_start_date = market_train_df['time'].head(1).values[0]\n",
    "market_end_date = market_train_df['time'].tail(1).values[0]\n",
    "news_start_date = news_train_df['time'].head(1).values[0]\n",
    "news_end_date = news_train_df['time'].tail(1).values[0]\n",
    "print (\"market train dates:\", market_start_date,\"to\",market_end_date)\n",
    "print (\"news   train dates:\", news_start_date,  \"to\",news_end_date)\n",
    "print (\"market train shape:\", market_train_df.shape)\n",
    "print (\"news   train shape:\", news_train_df.shape)\n",
    "print (\"market train memory (MB):\",df_memoryMB(market_train_df))\n",
    "print (\"news   train memory (MB):\",df_memoryMB(news_train_df))\n",
    "#show_year_rows_before_time_conversion(market_train_df, news_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d6a02c64a7d6209a2c455f1831ba2b6fd528e0e"
   },
   "source": [
    "# Training Data - Market\n",
    "Show summary of `market_train_df`\n",
    "\n",
    "Change 'time' to an integer YYYYMMDD. (Integer not string for flexability)<br>\n",
    "\n",
    "Keep all universe entries for now.<br>\n",
    "\n",
    "There are 93054 missing entries in `returnsOpenPrevMktres10` column so fill this in using `returnsOpenNextMktres10` and drop any rows that have missing cells (ie. NaN) in critical columns.<br>\n",
    "\n",
    "*Note on the columns:*<br>\n",
    "Residualised returns are surely the most useful columns since they show the real picture, ie. they take into consideration splits, dividends and overall market returns.<br>\n",
    "\n",
    "*Note on Benchmark Returns:*<br>\n",
    "`Raw - Mktres` doesn't equal benchmark returns because specific splits/dividends are taken into account, eg.<br>\n",
    "`Date      : Asset : Days:  Raw      -  Mktres   = Benchmark + Split/Dividend Calc.`<br>\n",
    "`2016-06-30: AAPL.O:    1:  0.005002 -  0.003236 = 0.001766`<br>\n",
    "`2016-06-30: AAPL.O:   10: -0.020840 - -0.025209 = 0.004369`<br>\n",
    "`2016-06-30: GOOG.O:    1:  0.003616 -  0.003339 = 0.00027`<br>\n",
    "`2016-06-30: GOOG.O:   10: -0.041180 - -0.046054 = 0.004874`<br>\n",
    "\n",
    "*Would the mean of mktres1 and the mean of mktres10 be more or less equal to the benchmark?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2531b4c1e069783959b92056e728107d2e747bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape (2946739, 17)\n",
      "................."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>dType</th>\n",
       "      <th>Type</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>&lt;class 'numpy.int64'&gt;</td>\n",
       "      <td>2946739</td>\n",
       "      <td>[1126217, 1126218, 1126219, 1126220, 1126221, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>&lt;class 'numpy.int64'&gt;</td>\n",
       "      <td>1762</td>\n",
       "      <td>[20100104, 20100105, 20100106, 20100107, 20100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assetCode</th>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>3327</td>\n",
       "      <td>[A.N, AAI.N, AAP.N, AAPL.O, AAV.N, AAWW.O, AB....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assetName</th>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>3139</td>\n",
       "      <td>[Agilent Technologies Inc, AirTran Holdings In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>1945568</td>\n",
       "      <td>[2729240.0, 3436803.0, 1701655.0, 17633150.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>51654</td>\n",
       "      <td>[31.3, 5.18, 40.38, 214.01, 6.83, 38.2, 28.4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>43177</td>\n",
       "      <td>[31.39, 5.26, 40.7, 213.5, 6.61, 37.82, 28.51,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsClosePrevRaw1</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2176952</td>\n",
       "      <td>[0.007402639201802952, -0.007662835249042098, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenPrevRaw1</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2155901</td>\n",
       "      <td>[0.011275773195873029, 0.011538461538461496, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsClosePrevMktres1</th>\n",
       "      <td>10668</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2936037</td>\n",
       "      <td>[-0.002343702903903977, -0.027851042066156708,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenPrevMktres1</th>\n",
       "      <td>10676</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2936006</td>\n",
       "      <td>[0.010532228852100627, 0.021130641959079773, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsClosePrevRaw10</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2533323</td>\n",
       "      <td>[0.06317934782608936, 0.005825242718446422, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenPrevRaw10</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2510479</td>\n",
       "      <td>[0.06587436332767194, 0.005736137667303964, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsClosePrevMktres10</th>\n",
       "      <td>57306</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2889409</td>\n",
       "      <td>[0.02726959238112493, 0.08355775694246992, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenPrevMktres10</th>\n",
       "      <td>57350</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2889390</td>\n",
       "      <td>[0.060092319173860737, 0.030177505574295313, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenNextMktres10</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2946739</td>\n",
       "      <td>[-0.04019684603803594, 0.06125265695209382, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>universe</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Null    dType                     Type   Unique  \\\n",
       "Unnamed: 0                    0    int64    <class 'numpy.int64'>  2946739   \n",
       "time                          0    int64    <class 'numpy.int64'>     1762   \n",
       "assetCode                     0   object            <class 'str'>     3327   \n",
       "assetName                     0   object            <class 'str'>     3139   \n",
       "volume                        0  float64  <class 'numpy.float64'>  1945568   \n",
       "close                         0  float64  <class 'numpy.float64'>    51654   \n",
       "open                          0  float64  <class 'numpy.float64'>    43177   \n",
       "returnsClosePrevRaw1          0  float64  <class 'numpy.float64'>  2176952   \n",
       "returnsOpenPrevRaw1           0  float64  <class 'numpy.float64'>  2155901   \n",
       "returnsClosePrevMktres1   10668  float64  <class 'numpy.float64'>  2936037   \n",
       "returnsOpenPrevMktres1    10676  float64  <class 'numpy.float64'>  2936006   \n",
       "returnsClosePrevRaw10         0  float64  <class 'numpy.float64'>  2533323   \n",
       "returnsOpenPrevRaw10          0  float64  <class 'numpy.float64'>  2510479   \n",
       "returnsClosePrevMktres10  57306  float64  <class 'numpy.float64'>  2889409   \n",
       "returnsOpenPrevMktres10   57350  float64  <class 'numpy.float64'>  2889390   \n",
       "returnsOpenNextMktres10       0  float64  <class 'numpy.float64'>  2946739   \n",
       "universe                      0  float64  <class 'numpy.float64'>        2   \n",
       "\n",
       "                                                                   Examples  \n",
       "Unnamed: 0                [1126217, 1126218, 1126219, 1126220, 1126221, ...  \n",
       "time                      [20100104, 20100105, 20100106, 20100107, 20100...  \n",
       "assetCode                 [A.N, AAI.N, AAP.N, AAPL.O, AAV.N, AAWW.O, AB....  \n",
       "assetName                 [Agilent Technologies Inc, AirTran Holdings In...  \n",
       "volume                    [2729240.0, 3436803.0, 1701655.0, 17633150.0, ...  \n",
       "close                     [31.3, 5.18, 40.38, 214.01, 6.83, 38.2, 28.4, ...  \n",
       "open                      [31.39, 5.26, 40.7, 213.5, 6.61, 37.82, 28.51,...  \n",
       "returnsClosePrevRaw1      [0.007402639201802952, -0.007662835249042098, ...  \n",
       "returnsOpenPrevRaw1       [0.011275773195873029, 0.011538461538461496, -...  \n",
       "returnsClosePrevMktres1   [-0.002343702903903977, -0.027851042066156708,...  \n",
       "returnsOpenPrevMktres1    [0.010532228852100627, 0.021130641959079773, -...  \n",
       "returnsClosePrevRaw10     [0.06317934782608936, 0.005825242718446422, -0...  \n",
       "returnsOpenPrevRaw10      [0.06587436332767194, 0.005736137667303964, 0....  \n",
       "returnsClosePrevMktres10  [0.02726959238112493, 0.08355775694246992, -0....  \n",
       "returnsOpenPrevMktres10   [0.060092319173860737, 0.030177505574295313, -...  \n",
       "returnsOpenNextMktres10   [-0.04019684603803594, 0.06125265695209382, -0...  \n",
       "universe                                                         [1.0, 0.0]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(market_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7f7a7dc76d1383094cc269814e7b85e94f4aa296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted market time to integer YYYYMMDD (and removed time)\n",
      "(4072956, 16)\n",
      "DataFrame shape (4072956, 16)\n",
      "................"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null</th>\n",
       "      <th>dType</th>\n",
       "      <th>Type</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "      <td>&lt;class 'numpy.int64'&gt;</td>\n",
       "      <td>2498</td>\n",
       "      <td>[20070201, 20070202, 20070205, 20070206, 20070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assetCode</th>\n",
       "      <td>0</td>\n",
       "      <td>object</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>3780</td>\n",
       "      <td>[A.N, AAI.N, AAP.N, AAPL.O, ABB.N, ABC.N, ABD....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assetName</th>\n",
       "      <td>0</td>\n",
       "      <td>category</td>\n",
       "      <td>&lt;class 'str'&gt;</td>\n",
       "      <td>3511</td>\n",
       "      <td>[Agilent Technologies Inc, AirTran Holdings In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2392152</td>\n",
       "      <td>[2606900.0, 2051600.0, 1164800.0, 23747329.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>55434</td>\n",
       "      <td>[32.19, 11.12, 37.51, 84.74, 18.02, 52.37, 23....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>46627</td>\n",
       "      <td>[32.17, 11.08, 37.99, 86.23, 18.01, 52.4, 24.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsClosePrevRaw1</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2903234</td>\n",
       "      <td>[0.005937500000000151, 0.004516711833784992, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenPrevRaw1</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2866950</td>\n",
       "      <td>[0.005312499999997611, -0.007168458781361964, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsClosePrevMktres1</th>\n",
       "      <td>15980</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>4056918</td>\n",
       "      <td>[nan, -0.019682215017981994, 0.010968392128086...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenPrevMktres1</th>\n",
       "      <td>15988</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>4056911</td>\n",
       "      <td>[nan, -0.0018015662911102332, -0.0084749011130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsClosePrevRaw10</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>3416981</td>\n",
       "      <td>[-0.0018604651162773544, -0.07870753935376973,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenPrevRaw10</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>3380335</td>\n",
       "      <td>[0.0006220839813353418, -0.08806584362139924, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsClosePrevMktres10</th>\n",
       "      <td>93010</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>3979922</td>\n",
       "      <td>[nan, 0.03909832265804995, 0.00660064246402183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenPrevMktres10</th>\n",
       "      <td>93054</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>3979903</td>\n",
       "      <td>[nan, 0.007461258789715073, -0.010883714154861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returnsOpenNextMktres10</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>4072956</td>\n",
       "      <td>[0.034672039756225945, 0.0278032796083542, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>universe</th>\n",
       "      <td>0</td>\n",
       "      <td>float64</td>\n",
       "      <td>&lt;class 'numpy.float64'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Null                        ...                                                                   Examples\n",
       "time                          0                        ...                          [20070201, 20070202, 20070205, 20070206, 20070...\n",
       "assetCode                     0                        ...                          [A.N, AAI.N, AAP.N, AAPL.O, ABB.N, ABC.N, ABD....\n",
       "assetName                     0                        ...                          [Agilent Technologies Inc, AirTran Holdings In...\n",
       "volume                        0                        ...                          [2606900.0, 2051600.0, 1164800.0, 23747329.0, ...\n",
       "close                         0                        ...                          [32.19, 11.12, 37.51, 84.74, 18.02, 52.37, 23....\n",
       "open                          0                        ...                          [32.17, 11.08, 37.99, 86.23, 18.01, 52.4, 24.1...\n",
       "returnsClosePrevRaw1          0                        ...                          [0.005937500000000151, 0.004516711833784992, -...\n",
       "returnsOpenPrevRaw1           0                        ...                          [0.005312499999997611, -0.007168458781361964, ...\n",
       "returnsClosePrevMktres1   15980                        ...                          [nan, -0.019682215017981994, 0.010968392128086...\n",
       "returnsOpenPrevMktres1    15988                        ...                          [nan, -0.0018015662911102332, -0.0084749011130...\n",
       "returnsClosePrevRaw10         0                        ...                          [-0.0018604651162773544, -0.07870753935376973,...\n",
       "returnsOpenPrevRaw10          0                        ...                          [0.0006220839813353418, -0.08806584362139924, ...\n",
       "returnsClosePrevMktres10  93010                        ...                          [nan, 0.03909832265804995, 0.00660064246402183...\n",
       "returnsOpenPrevMktres10   93054                        ...                          [nan, 0.007461258789715073, -0.010883714154861...\n",
       "returnsOpenNextMktres10       0                        ...                          [0.034672039756225945, 0.0278032796083542, 0.0...\n",
       "universe                      0                        ...                                                                 [1.0, 0.0]\n",
       "\n",
       "[16 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if market_train_df['time'].dtype != 'int':\n",
    "    market_train_df['time'] = market_train_df['time'].dt.strftime(date_format='%Y%m%d').astype(int).values\n",
    "    print (\"Converted market time to integer YYYYMMDD (and removed time)\")\n",
    "\n",
    "# returnsOpenPrevMktres10's 93054 empty values can be filled using returnsOpenNextMktres10\n",
    "# NOTE: asset data will leak into adjacent assets; so we'll remove the first and last 11 days, below. \n",
    "# ALSO: drop if any of volume, returnsOpenPrevMktres10 or returnsOpenNextMktres10 are NaN\n",
    "#if (market_train_df['returnsOpenPrevMktres10'].isna().sum() > 0):\n",
    "#    market_train_df.sort_values(by=['assetCode','time'], inplace=True)\n",
    "#    market_train_df['returnsOpenPrevMktres10'] = market_train_df['returnsOpenNextMktres10'].shift(11)\n",
    "#    market_train_df.sort_values(by=['time','assetCode'], inplace=True)\n",
    "#    market_train_df.dropna(subset=['volume', 'returnsOpenPrevMktres10', 'returnsOpenNextMktres10'], how='any', inplace=True)\n",
    "#    print (\"Filled returnsOpenPrevMktres10 and dropped rows with NaN in critical columns\")\n",
    "\n",
    "if ('universe' in market_train_df.columns):\n",
    "    universe0_count = market_train_df['universe'].loc[market_train_df['universe'] != 1.0].count()\n",
    "    market_train_df = market_train_df.loc[market_train_df['universe'] == 1.0]\n",
    "    market_train_df.drop(columns=['universe'], inplace=True)\n",
    "    print (\"Removed {:d} rows where universe != 1 and dropped column\".format(universe0_count))\n",
    "\n",
    "print(market_train_df.shape)\n",
    "summary(market_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eeb49c7cc8204f1d0598002980629cc6ed15e4d2"
   },
   "source": [
    "**Set Market sample based on date range (chosen after adding whatever cols above)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "680fff8633a57d0808a95c949405a072ad74a8f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting market samples from 20100101 to 20161230\n"
     ]
    }
   ],
   "source": [
    "#trainfrom = 20100101\n",
    "#trainto   = 20161230\n",
    "#print (\"Getting market samples from\",trainfrom,\"to\",trainto)\n",
    "#market_sample = market_train_df.loc[get_dates(market_train_df, datefrom=trainfrom, dateto=trainto)]\n",
    "market_sample = market_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "51336930fd2ddc83f842126175c4f23c1c97eee2"
   },
   "source": [
    "#### Example six months look at Google (Alphabet) GOOG.O:\n",
    "* a table shows `returnsOpenPrevMktres10` and `returnsOpenNextMktres10` are the same 10 trading days apart.\n",
    "* the graph shows that GOOG.O in blue (no voting rights) and GOOGL.O in orange (voting rights) track one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "e8218be3908055babf22df440f2de08d328400f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 months of GOOG.O (127, 17)\n",
      "6 months of GOOGL.O (127, 17)\n",
      "First 20 lines of GOOG.O\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>assetCode</th>\n",
       "      <th>assetName</th>\n",
       "      <th>returnsOpenPrevMktres10</th>\n",
       "      <th>returnsOpenNextMktres10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2715726</th>\n",
       "      <td>20160701</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>-0.037190</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717523</th>\n",
       "      <td>20160705</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>-0.016026</td>\n",
       "      <td>0.009272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719322</th>\n",
       "      <td>20160706</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>-0.011616</td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721120</th>\n",
       "      <td>20160707</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>-0.007512</td>\n",
       "      <td>0.016169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722917</th>\n",
       "      <td>20160708</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>-0.004890</td>\n",
       "      <td>0.015183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724716</th>\n",
       "      <td>20160711</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.029450</td>\n",
       "      <td>0.007083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726516</th>\n",
       "      <td>20160712</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>-0.010521</td>\n",
       "      <td>0.009625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728316</th>\n",
       "      <td>20160713</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>-0.032960</td>\n",
       "      <td>0.030083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730113</th>\n",
       "      <td>20160714</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>0.062852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731910</th>\n",
       "      <td>20160715</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>-0.002983</td>\n",
       "      <td>0.048494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733708</th>\n",
       "      <td>20160718</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.051024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735506</th>\n",
       "      <td>20160719</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.043264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737304</th>\n",
       "      <td>20160720</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>0.045226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739103</th>\n",
       "      <td>20160721</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.042573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740903</th>\n",
       "      <td>20160722</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.016169</td>\n",
       "      <td>0.054233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742700</th>\n",
       "      <td>20160725</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.054939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744496</th>\n",
       "      <td>20160726</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>0.060020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746293</th>\n",
       "      <td>20160727</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.049452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748097</th>\n",
       "      <td>20160728</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.030083</td>\n",
       "      <td>0.009072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749904</th>\n",
       "      <td>20160729</td>\n",
       "      <td>GOOG.O</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>0.062852</td>\n",
       "      <td>0.027660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time assetCode     assetName  returnsOpenPrevMktres10  \\\n",
       "2715726  20160701    GOOG.O  Alphabet Inc                -0.037190   \n",
       "2717523  20160705    GOOG.O  Alphabet Inc                -0.016026   \n",
       "2719322  20160706    GOOG.O  Alphabet Inc                -0.011616   \n",
       "2721120  20160707    GOOG.O  Alphabet Inc                -0.007512   \n",
       "2722917  20160708    GOOG.O  Alphabet Inc                -0.004890   \n",
       "2724716  20160711    GOOG.O  Alphabet Inc                 0.029450   \n",
       "2726516  20160712    GOOG.O  Alphabet Inc                -0.010521   \n",
       "2728316  20160713    GOOG.O  Alphabet Inc                -0.032960   \n",
       "2730113  20160714    GOOG.O  Alphabet Inc                -0.019475   \n",
       "2731910  20160715    GOOG.O  Alphabet Inc                -0.002983   \n",
       "2733708  20160718    GOOG.O  Alphabet Inc                 0.001151   \n",
       "2735506  20160719    GOOG.O  Alphabet Inc                 0.000302   \n",
       "2737304  20160720    GOOG.O  Alphabet Inc                 0.009272   \n",
       "2739103  20160721    GOOG.O  Alphabet Inc                 0.007033   \n",
       "2740903  20160722    GOOG.O  Alphabet Inc                 0.016169   \n",
       "2742700  20160725    GOOG.O  Alphabet Inc                 0.015183   \n",
       "2744496  20160726    GOOG.O  Alphabet Inc                 0.007083   \n",
       "2746293  20160727    GOOG.O  Alphabet Inc                 0.009625   \n",
       "2748097  20160728    GOOG.O  Alphabet Inc                 0.030083   \n",
       "2749904  20160729    GOOG.O  Alphabet Inc                 0.062852   \n",
       "\n",
       "         returnsOpenNextMktres10  \n",
       "2715726                 0.000302  \n",
       "2717523                 0.009272  \n",
       "2719322                 0.007033  \n",
       "2721120                 0.016169  \n",
       "2722917                 0.015183  \n",
       "2724716                 0.007083  \n",
       "2726516                 0.009625  \n",
       "2728316                 0.030083  \n",
       "2730113                 0.062852  \n",
       "2731910                 0.048494  \n",
       "2733708                 0.051024  \n",
       "2735506                 0.043264  \n",
       "2737304                 0.045226  \n",
       "2739103                 0.042573  \n",
       "2740903                 0.054233  \n",
       "2742700                 0.054939  \n",
       "2744496                 0.060020  \n",
       "2746293                 0.049452  \n",
       "2748097                 0.009072  \n",
       "2749904                 0.027660  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For expressions you can set: flags=re.IGNORECASE, regex=True\n",
    "def get_asset(df, cols, acol, asset, flags=0, regex=False, datefrom=None, dateto=None):\n",
    "    search_asset = ((df[acol].str.contains(asset, flags=flags, regex=regex)) &\n",
    "                    get_dates(df, datefrom=datefrom, dateto=dateto))\n",
    "    return df[cols].loc[search_asset]\n",
    "\n",
    "eg_from = 20160701\n",
    "eg_to   = 20161230\n",
    "eg1_df = get_asset(market_train_df, market_train_df.columns, 'assetCode', 'GOOG.O', datefrom=eg_from, dateto=eg_to)\n",
    "eg2_df = get_asset(market_train_df, market_train_df.columns, 'assetCode', 'GOOGL.O', datefrom=eg_from, dateto=eg_to)\n",
    "print (\"6 months of GOOG.O\",eg1_df.shape)\n",
    "print (\"6 months of GOOGL.O\",eg2_df.shape)\n",
    "print (\"First 20 lines of GOOG.O\")\n",
    "eg1_df[['time','assetCode','assetName','returnsOpenPrevMktres10','returnsOpenNextMktres10']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "8fa0a93e643a9de8ac3fc832aaa07942ba6f95f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "type": "scatter",
         "uid": "b73c2a6c-4362-4a51-9487-23fcecd80e27",
         "x": [
          20160701,
          20160705,
          20160706,
          20160707,
          20160708,
          20160711,
          20160712,
          20160713,
          20160714,
          20160715,
          20160718,
          20160719,
          20160720,
          20160721,
          20160722,
          20160725,
          20160726,
          20160727,
          20160728,
          20160729,
          20160801,
          20160802,
          20160803,
          20160804,
          20160805,
          20160808,
          20160809,
          20160810,
          20160811,
          20160812,
          20160815,
          20160816,
          20160817,
          20160818,
          20160819,
          20160822,
          20160823,
          20160824,
          20160825,
          20160826,
          20160829,
          20160830,
          20160831,
          20160901,
          20160902,
          20160906,
          20160907,
          20160908,
          20160909,
          20160912,
          20160913,
          20160914,
          20160915,
          20160916,
          20160919,
          20160920,
          20160921,
          20160922,
          20160923,
          20160926,
          20160927,
          20160928,
          20160929,
          20160930,
          20161003,
          20161004,
          20161005,
          20161006,
          20161007,
          20161010,
          20161011,
          20161012,
          20161013,
          20161014,
          20161017,
          20161018,
          20161019,
          20161020,
          20161021,
          20161024,
          20161025,
          20161026,
          20161027,
          20161028,
          20161031,
          20161101,
          20161102,
          20161103,
          20161104,
          20161107,
          20161108,
          20161109,
          20161110,
          20161111,
          20161114,
          20161115,
          20161116,
          20161117,
          20161118,
          20161121,
          20161122,
          20161123,
          20161125,
          20161128,
          20161129,
          20161130,
          20161201,
          20161202,
          20161205,
          20161206,
          20161207,
          20161208,
          20161209,
          20161212,
          20161213,
          20161214,
          20161215,
          20161216,
          20161219,
          20161220,
          20161221,
          20161222,
          20161223,
          20161227,
          20161228,
          20161229,
          20161230
         ],
         "y": [
          -0.03719039367506632,
          -0.016025641878571972,
          -0.011616257149299812,
          -0.0075120845421691096,
          -0.00489019738735986,
          0.029450452785506714,
          -0.010520904270269887,
          -0.032960388830574075,
          -0.019475158752833163,
          -0.0029831354328057405,
          0.0011509157831710304,
          0.000301722572258252,
          0.009272321414605987,
          0.007033444862694083,
          0.016169373575389688,
          0.015183209393835087,
          0.007083004729545636,
          0.009624667857687084,
          0.030083089937058643,
          0.06285159693474714,
          0.04849405504642687,
          0.05102446155047877,
          0.04326395863525842,
          0.04522644322893563,
          0.04257262334154275,
          0.05423250089448446,
          0.054939175534539836,
          0.060020213533049475,
          0.04945247757199678,
          0.00907219520046477,
          0.027660291558741952,
          0.011816508717567516,
          0.008449778434717031,
          0.0076070583643967436,
          0.001933888643619868,
          -0.011598750285197641,
          -0.0048549666371373755,
          -0.01623336819876466,
          -0.02178252938919562,
          -0.010952955030405071,
          -0.004513442864855987,
          -0.007478285508429003,
          -0.008850821550738852,
          0.00025208507083490823,
          0.008310334857631014,
          0.00018318539447517243,
          0.009857593747005669,
          0.013519220957097434,
          0.008735733690456259,
          0.012748134668791426,
          0.004849908793742334,
          0.005810528004489109,
          0.006638540390665044,
          0.005093569517310051,
          0.0025300197733769906,
          -0.0036679687237563202,
          -0.006663635760268629,
          0.002760739701903316,
          0.02055211986181903,
          0.02112162487001629,
          0.016325450594727516,
          0.008822165481142473,
          0.004923511904911321,
          0.004095360719558532,
          -0.0060917565629318654,
          0.002050853989173216,
          0.004310969756902243,
          0.0038465019552431025,
          -0.005146944223776763,
          -0.0071617525245635015,
          0.008403107886646789,
          0.016574956902634573,
          0.013291713529782315,
          0.012921587276188185,
          0.017824049459478852,
          0.02320283861068892,
          0.029204191272341782,
          0.034646238325806815,
          0.02421184393980241,
          0.036826166606173966,
          0.038846186767791537,
          0.02885523033496505,
          0.0246048941554704,
          0.034008790741907075,
          0.020103701278841292,
          -0.005477103990610276,
          -0.01601805434825006,
          -0.015480714705726447,
          -0.004604200320392764,
          0.010779009459579944,
          -0.01859818087547909,
          -0.02641832919540471,
          -0.031317000962843435,
          -0.07439252013664199,
          -0.052610478054642314,
          -0.04310452366158677,
          -0.02171080061541681,
          0.0026531267481555536,
          0.016786027503789047,
          -0.024659039132483816,
          -0.022852816387161082,
          -0.026131841357845038,
          -0.040576505595490434,
          -0.004394933887549911,
          0.012660327321507578,
          0.02058261989608484,
          -0.003800524649576244,
          -0.03311575983663385,
          -0.02203543896349785,
          -0.002865436164690191,
          -0.01747803064090617,
          -0.0036504005076917947,
          0.012013960961028526,
          0.02290852065454494,
          0.017672021362076795,
          0.02418271113963628,
          0.04389278668162668,
          0.04964508602625384,
          0.01900118910955564,
          0.012796785946663013,
          -0.0020739824302713067,
          0.005830764422291291,
          0.003294889578231033,
          0.00022341186797042705,
          -0.006745333721721513,
          -0.0010946176989472462,
          -0.01637592045591516
         ]
        },
        {
         "type": "scatter",
         "uid": "4150dc66-314b-467f-b3ef-2e734e063df0",
         "x": [
          20160701,
          20160705,
          20160706,
          20160707,
          20160708,
          20160711,
          20160712,
          20160713,
          20160714,
          20160715,
          20160718,
          20160719,
          20160720,
          20160721,
          20160722,
          20160725,
          20160726,
          20160727,
          20160728,
          20160729,
          20160801,
          20160802,
          20160803,
          20160804,
          20160805,
          20160808,
          20160809,
          20160810,
          20160811,
          20160812,
          20160815,
          20160816,
          20160817,
          20160818,
          20160819,
          20160822,
          20160823,
          20160824,
          20160825,
          20160826,
          20160829,
          20160830,
          20160831,
          20160901,
          20160902,
          20160906,
          20160907,
          20160908,
          20160909,
          20160912,
          20160913,
          20160914,
          20160915,
          20160916,
          20160919,
          20160920,
          20160921,
          20160922,
          20160923,
          20160926,
          20160927,
          20160928,
          20160929,
          20160930,
          20161003,
          20161004,
          20161005,
          20161006,
          20161007,
          20161010,
          20161011,
          20161012,
          20161013,
          20161014,
          20161017,
          20161018,
          20161019,
          20161020,
          20161021,
          20161024,
          20161025,
          20161026,
          20161027,
          20161028,
          20161031,
          20161101,
          20161102,
          20161103,
          20161104,
          20161107,
          20161108,
          20161109,
          20161110,
          20161111,
          20161114,
          20161115,
          20161116,
          20161117,
          20161118,
          20161121,
          20161122,
          20161123,
          20161125,
          20161128,
          20161129,
          20161130,
          20161201,
          20161202,
          20161205,
          20161206,
          20161207,
          20161208,
          20161209,
          20161212,
          20161213,
          20161214,
          20161215,
          20161216,
          20161219,
          20161220,
          20161221,
          20161222,
          20161223,
          20161227,
          20161228,
          20161229,
          20161230
         ],
         "y": [
          -0.03664732117979673,
          -0.019899331528839256,
          -0.01392230526076969,
          -0.0118736156943925,
          -0.00792217538693684,
          0.023409932046474992,
          -0.009601698005014423,
          -0.034521560073509185,
          -0.018855313762151358,
          -0.0002705513124361888,
          0.002950787278327795,
          0.013774940479983485,
          0.015784536780801044,
          0.010306949034296416,
          0.019482357415813417,
          0.02091350735678605,
          0.013427287545796059,
          0.02081546275283781,
          0.04217868801020838,
          0.07466090190442873,
          0.061653297803678675,
          0.061310020945403026,
          0.058634897500792524,
          0.05612531783013956,
          0.05621618635447577,
          0.06300618558520266,
          0.06112095008567395,
          0.06273367119924851,
          0.05353188387159925,
          0.0076254632988740426,
          0.02436919399849128,
          0.004617322451387126,
          0.0005844457345628969,
          0.008072993331063046,
          0.0022731977274223626,
          -0.010252700367058406,
          -0.0004069867154726957,
          -0.010827768750323269,
          -0.023998873336810247,
          -0.014091208779683674,
          -0.007481759907977278,
          -0.008583403406051055,
          -0.0097622402143521,
          -0.004309216697581971,
          0.004617590315884428,
          -0.00019758492645529884,
          0.013059190513600568,
          0.013310570932511794,
          0.012571210743654023,
          0.011752550144161015,
          0.008044468995111933,
          0.003614399116156894,
          0.005959696186968284,
          0.010351957451993113,
          0.0062979528715901975,
          -0.0006123263098821129,
          -0.010250003433181068,
          0.005444230350134993,
          0.020213852262288497,
          0.021941470198699426,
          0.011138532444623985,
          0.010421441746501704,
          0.007816435734625655,
          0.002539657740426486,
          -0.004145533837101751,
          0.0013520751735404367,
          0.002970555233133109,
          -0.0037624679137780244,
          -0.008762057950193929,
          -0.0077759362024162285,
          0.011231408750440215,
          0.016031709073326076,
          0.008268116350115252,
          0.00930742999522772,
          0.01274274287316155,
          0.018257011703824474,
          0.02676047991456013,
          0.032418726762741934,
          0.0218018849816873,
          0.03430663247363345,
          0.03061536551596765,
          0.0187172453870019,
          0.020311463690671657,
          0.027676883699476656,
          0.020401410190139482,
          -0.003444153643420368,
          -0.01323965183726717,
          -0.023208969596910985,
          -0.008287088378489856,
          0.0065811034748752,
          -0.021286574582731217,
          -0.02429108790378256,
          -0.03469961030549545,
          -0.0747294414563592,
          -0.06320242079788617,
          -0.0514335225041429,
          -0.03181711088257639,
          0.0045964475507713175,
          0.01426157475401246,
          -0.02718652973298458,
          -0.023094122652412195,
          -0.02396482943578867,
          -0.03926923395696776,
          -0.005662724179273257,
          0.014143224968360018,
          0.021507874407425676,
          0.0043330469056092145,
          -0.030104948505228112,
          -0.02574631992173887,
          -0.0021081184932341627,
          -0.01323866489606881,
          -0.0017790902665010527,
          0.016501078274096144,
          0.0283668919185708,
          0.02443177800142847,
          0.028477645993465407,
          0.046298265439075566,
          0.0544558035865159,
          0.031291393205312074,
          0.016594761522891008,
          -7.821576366529026e-05,
          0.0005890063415195588,
          0.0001443790594486856,
          -0.002274513643228138,
          -0.005424926019384978,
          2.756167859737507e-05,
          -0.015378615787593943
         ]
        }
       ],
       "layout": {
        "title": "returnsOpenPrevMktres10: GOOG.O vs GOOGL.O",
        "xaxis": {
         "showticklabels": false,
         "title": "Date"
        },
        "yaxis": {
         "title": "USD"
        }
       }
      },
      "text/html": [
       "<div id=\"198bee6c-ac3a-417e-9a02-6eec495b72cd\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"198bee6c-ac3a-417e-9a02-6eec495b72cd\", [{\"x\": [20160701, 20160705, 20160706, 20160707, 20160708, 20160711, 20160712, 20160713, 20160714, 20160715, 20160718, 20160719, 20160720, 20160721, 20160722, 20160725, 20160726, 20160727, 20160728, 20160729, 20160801, 20160802, 20160803, 20160804, 20160805, 20160808, 20160809, 20160810, 20160811, 20160812, 20160815, 20160816, 20160817, 20160818, 20160819, 20160822, 20160823, 20160824, 20160825, 20160826, 20160829, 20160830, 20160831, 20160901, 20160902, 20160906, 20160907, 20160908, 20160909, 20160912, 20160913, 20160914, 20160915, 20160916, 20160919, 20160920, 20160921, 20160922, 20160923, 20160926, 20160927, 20160928, 20160929, 20160930, 20161003, 20161004, 20161005, 20161006, 20161007, 20161010, 20161011, 20161012, 20161013, 20161014, 20161017, 20161018, 20161019, 20161020, 20161021, 20161024, 20161025, 20161026, 20161027, 20161028, 20161031, 20161101, 20161102, 20161103, 20161104, 20161107, 20161108, 20161109, 20161110, 20161111, 20161114, 20161115, 20161116, 20161117, 20161118, 20161121, 20161122, 20161123, 20161125, 20161128, 20161129, 20161130, 20161201, 20161202, 20161205, 20161206, 20161207, 20161208, 20161209, 20161212, 20161213, 20161214, 20161215, 20161216, 20161219, 20161220, 20161221, 20161222, 20161223, 20161227, 20161228, 20161229, 20161230], \"y\": [-0.03719039367506632, -0.016025641878571972, -0.011616257149299812, -0.0075120845421691096, -0.00489019738735986, 0.029450452785506714, -0.010520904270269887, -0.032960388830574075, -0.019475158752833163, -0.0029831354328057405, 0.0011509157831710304, 0.000301722572258252, 0.009272321414605987, 0.007033444862694083, 0.016169373575389688, 0.015183209393835087, 0.007083004729545636, 0.009624667857687084, 0.030083089937058643, 0.06285159693474714, 0.04849405504642687, 0.05102446155047877, 0.04326395863525842, 0.04522644322893563, 0.04257262334154275, 0.05423250089448446, 0.054939175534539836, 0.060020213533049475, 0.04945247757199678, 0.00907219520046477, 0.027660291558741952, 0.011816508717567516, 0.008449778434717031, 0.0076070583643967436, 0.001933888643619868, -0.011598750285197641, -0.0048549666371373755, -0.01623336819876466, -0.02178252938919562, -0.010952955030405071, -0.004513442864855987, -0.007478285508429003, -0.008850821550738852, 0.00025208507083490823, 0.008310334857631014, 0.00018318539447517243, 0.009857593747005669, 0.013519220957097434, 0.008735733690456259, 0.012748134668791426, 0.004849908793742334, 0.005810528004489109, 0.006638540390665044, 0.005093569517310051, 0.0025300197733769906, -0.0036679687237563202, -0.006663635760268629, 0.002760739701903316, 0.02055211986181903, 0.02112162487001629, 0.016325450594727516, 0.008822165481142473, 0.004923511904911321, 0.004095360719558532, -0.0060917565629318654, 0.002050853989173216, 0.004310969756902243, 0.0038465019552431025, -0.005146944223776763, -0.0071617525245635015, 0.008403107886646789, 0.016574956902634573, 0.013291713529782315, 0.012921587276188185, 0.017824049459478852, 0.02320283861068892, 0.029204191272341782, 0.034646238325806815, 0.02421184393980241, 0.036826166606173966, 0.038846186767791537, 0.02885523033496505, 0.0246048941554704, 0.034008790741907075, 0.020103701278841292, -0.005477103990610276, -0.01601805434825006, -0.015480714705726447, -0.004604200320392764, 0.010779009459579944, -0.01859818087547909, -0.02641832919540471, -0.031317000962843435, -0.07439252013664199, -0.052610478054642314, -0.04310452366158677, -0.02171080061541681, 0.0026531267481555536, 0.016786027503789047, -0.024659039132483816, -0.022852816387161082, -0.026131841357845038, -0.040576505595490434, -0.004394933887549911, 0.012660327321507578, 0.02058261989608484, -0.003800524649576244, -0.03311575983663385, -0.02203543896349785, -0.002865436164690191, -0.01747803064090617, -0.0036504005076917947, 0.012013960961028526, 0.02290852065454494, 0.017672021362076795, 0.02418271113963628, 0.04389278668162668, 0.04964508602625384, 0.01900118910955564, 0.012796785946663013, -0.0020739824302713067, 0.005830764422291291, 0.003294889578231033, 0.00022341186797042705, -0.006745333721721513, -0.0010946176989472462, -0.01637592045591516], \"type\": \"scatter\", \"uid\": \"b73c2a6c-4362-4a51-9487-23fcecd80e27\"}, {\"x\": [20160701, 20160705, 20160706, 20160707, 20160708, 20160711, 20160712, 20160713, 20160714, 20160715, 20160718, 20160719, 20160720, 20160721, 20160722, 20160725, 20160726, 20160727, 20160728, 20160729, 20160801, 20160802, 20160803, 20160804, 20160805, 20160808, 20160809, 20160810, 20160811, 20160812, 20160815, 20160816, 20160817, 20160818, 20160819, 20160822, 20160823, 20160824, 20160825, 20160826, 20160829, 20160830, 20160831, 20160901, 20160902, 20160906, 20160907, 20160908, 20160909, 20160912, 20160913, 20160914, 20160915, 20160916, 20160919, 20160920, 20160921, 20160922, 20160923, 20160926, 20160927, 20160928, 20160929, 20160930, 20161003, 20161004, 20161005, 20161006, 20161007, 20161010, 20161011, 20161012, 20161013, 20161014, 20161017, 20161018, 20161019, 20161020, 20161021, 20161024, 20161025, 20161026, 20161027, 20161028, 20161031, 20161101, 20161102, 20161103, 20161104, 20161107, 20161108, 20161109, 20161110, 20161111, 20161114, 20161115, 20161116, 20161117, 20161118, 20161121, 20161122, 20161123, 20161125, 20161128, 20161129, 20161130, 20161201, 20161202, 20161205, 20161206, 20161207, 20161208, 20161209, 20161212, 20161213, 20161214, 20161215, 20161216, 20161219, 20161220, 20161221, 20161222, 20161223, 20161227, 20161228, 20161229, 20161230], \"y\": [-0.03664732117979673, -0.019899331528839256, -0.01392230526076969, -0.0118736156943925, -0.00792217538693684, 0.023409932046474992, -0.009601698005014423, -0.034521560073509185, -0.018855313762151358, -0.0002705513124361888, 0.002950787278327795, 0.013774940479983485, 0.015784536780801044, 0.010306949034296416, 0.019482357415813417, 0.02091350735678605, 0.013427287545796059, 0.02081546275283781, 0.04217868801020838, 0.07466090190442873, 0.061653297803678675, 0.061310020945403026, 0.058634897500792524, 0.05612531783013956, 0.05621618635447577, 0.06300618558520266, 0.06112095008567395, 0.06273367119924851, 0.05353188387159925, 0.0076254632988740426, 0.02436919399849128, 0.004617322451387126, 0.0005844457345628969, 0.008072993331063046, 0.0022731977274223626, -0.010252700367058406, -0.0004069867154726957, -0.010827768750323269, -0.023998873336810247, -0.014091208779683674, -0.007481759907977278, -0.008583403406051055, -0.0097622402143521, -0.004309216697581971, 0.004617590315884428, -0.00019758492645529884, 0.013059190513600568, 0.013310570932511794, 0.012571210743654023, 0.011752550144161015, 0.008044468995111933, 0.003614399116156894, 0.005959696186968284, 0.010351957451993113, 0.0062979528715901975, -0.0006123263098821129, -0.010250003433181068, 0.005444230350134993, 0.020213852262288497, 0.021941470198699426, 0.011138532444623985, 0.010421441746501704, 0.007816435734625655, 0.002539657740426486, -0.004145533837101751, 0.0013520751735404367, 0.002970555233133109, -0.0037624679137780244, -0.008762057950193929, -0.0077759362024162285, 0.011231408750440215, 0.016031709073326076, 0.008268116350115252, 0.00930742999522772, 0.01274274287316155, 0.018257011703824474, 0.02676047991456013, 0.032418726762741934, 0.0218018849816873, 0.03430663247363345, 0.03061536551596765, 0.0187172453870019, 0.020311463690671657, 0.027676883699476656, 0.020401410190139482, -0.003444153643420368, -0.01323965183726717, -0.023208969596910985, -0.008287088378489856, 0.0065811034748752, -0.021286574582731217, -0.02429108790378256, -0.03469961030549545, -0.0747294414563592, -0.06320242079788617, -0.0514335225041429, -0.03181711088257639, 0.0045964475507713175, 0.01426157475401246, -0.02718652973298458, -0.023094122652412195, -0.02396482943578867, -0.03926923395696776, -0.005662724179273257, 0.014143224968360018, 0.021507874407425676, 0.0043330469056092145, -0.030104948505228112, -0.02574631992173887, -0.0021081184932341627, -0.01323866489606881, -0.0017790902665010527, 0.016501078274096144, 0.0283668919185708, 0.02443177800142847, 0.028477645993465407, 0.046298265439075566, 0.0544558035865159, 0.031291393205312074, 0.016594761522891008, -7.821576366529026e-05, 0.0005890063415195588, 0.0001443790594486856, -0.002274513643228138, -0.005424926019384978, 2.756167859737507e-05, -0.015378615787593943], \"type\": \"scatter\", \"uid\": \"4150dc66-314b-467f-b3ef-2e734e063df0\"}], {\"title\": \"returnsOpenPrevMktres10: GOOG.O vs GOOGL.O\", \"xaxis\": {\"showticklabels\": false, \"title\": \"Date\"}, \"yaxis\": {\"title\": \"USD\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"198bee6c-ac3a-417e-9a02-6eec495b72cd\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"198bee6c-ac3a-417e-9a02-6eec495b72cd\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"198bee6c-ac3a-417e-9a02-6eec495b72cd\", [{\"x\": [20160701, 20160705, 20160706, 20160707, 20160708, 20160711, 20160712, 20160713, 20160714, 20160715, 20160718, 20160719, 20160720, 20160721, 20160722, 20160725, 20160726, 20160727, 20160728, 20160729, 20160801, 20160802, 20160803, 20160804, 20160805, 20160808, 20160809, 20160810, 20160811, 20160812, 20160815, 20160816, 20160817, 20160818, 20160819, 20160822, 20160823, 20160824, 20160825, 20160826, 20160829, 20160830, 20160831, 20160901, 20160902, 20160906, 20160907, 20160908, 20160909, 20160912, 20160913, 20160914, 20160915, 20160916, 20160919, 20160920, 20160921, 20160922, 20160923, 20160926, 20160927, 20160928, 20160929, 20160930, 20161003, 20161004, 20161005, 20161006, 20161007, 20161010, 20161011, 20161012, 20161013, 20161014, 20161017, 20161018, 20161019, 20161020, 20161021, 20161024, 20161025, 20161026, 20161027, 20161028, 20161031, 20161101, 20161102, 20161103, 20161104, 20161107, 20161108, 20161109, 20161110, 20161111, 20161114, 20161115, 20161116, 20161117, 20161118, 20161121, 20161122, 20161123, 20161125, 20161128, 20161129, 20161130, 20161201, 20161202, 20161205, 20161206, 20161207, 20161208, 20161209, 20161212, 20161213, 20161214, 20161215, 20161216, 20161219, 20161220, 20161221, 20161222, 20161223, 20161227, 20161228, 20161229, 20161230], \"y\": [-0.03719039367506632, -0.016025641878571972, -0.011616257149299812, -0.0075120845421691096, -0.00489019738735986, 0.029450452785506714, -0.010520904270269887, -0.032960388830574075, -0.019475158752833163, -0.0029831354328057405, 0.0011509157831710304, 0.000301722572258252, 0.009272321414605987, 0.007033444862694083, 0.016169373575389688, 0.015183209393835087, 0.007083004729545636, 0.009624667857687084, 0.030083089937058643, 0.06285159693474714, 0.04849405504642687, 0.05102446155047877, 0.04326395863525842, 0.04522644322893563, 0.04257262334154275, 0.05423250089448446, 0.054939175534539836, 0.060020213533049475, 0.04945247757199678, 0.00907219520046477, 0.027660291558741952, 0.011816508717567516, 0.008449778434717031, 0.0076070583643967436, 0.001933888643619868, -0.011598750285197641, -0.0048549666371373755, -0.01623336819876466, -0.02178252938919562, -0.010952955030405071, -0.004513442864855987, -0.007478285508429003, -0.008850821550738852, 0.00025208507083490823, 0.008310334857631014, 0.00018318539447517243, 0.009857593747005669, 0.013519220957097434, 0.008735733690456259, 0.012748134668791426, 0.004849908793742334, 0.005810528004489109, 0.006638540390665044, 0.005093569517310051, 0.0025300197733769906, -0.0036679687237563202, -0.006663635760268629, 0.002760739701903316, 0.02055211986181903, 0.02112162487001629, 0.016325450594727516, 0.008822165481142473, 0.004923511904911321, 0.004095360719558532, -0.0060917565629318654, 0.002050853989173216, 0.004310969756902243, 0.0038465019552431025, -0.005146944223776763, -0.0071617525245635015, 0.008403107886646789, 0.016574956902634573, 0.013291713529782315, 0.012921587276188185, 0.017824049459478852, 0.02320283861068892, 0.029204191272341782, 0.034646238325806815, 0.02421184393980241, 0.036826166606173966, 0.038846186767791537, 0.02885523033496505, 0.0246048941554704, 0.034008790741907075, 0.020103701278841292, -0.005477103990610276, -0.01601805434825006, -0.015480714705726447, -0.004604200320392764, 0.010779009459579944, -0.01859818087547909, -0.02641832919540471, -0.031317000962843435, -0.07439252013664199, -0.052610478054642314, -0.04310452366158677, -0.02171080061541681, 0.0026531267481555536, 0.016786027503789047, -0.024659039132483816, -0.022852816387161082, -0.026131841357845038, -0.040576505595490434, -0.004394933887549911, 0.012660327321507578, 0.02058261989608484, -0.003800524649576244, -0.03311575983663385, -0.02203543896349785, -0.002865436164690191, -0.01747803064090617, -0.0036504005076917947, 0.012013960961028526, 0.02290852065454494, 0.017672021362076795, 0.02418271113963628, 0.04389278668162668, 0.04964508602625384, 0.01900118910955564, 0.012796785946663013, -0.0020739824302713067, 0.005830764422291291, 0.003294889578231033, 0.00022341186797042705, -0.006745333721721513, -0.0010946176989472462, -0.01637592045591516], \"type\": \"scatter\", \"uid\": \"b73c2a6c-4362-4a51-9487-23fcecd80e27\"}, {\"x\": [20160701, 20160705, 20160706, 20160707, 20160708, 20160711, 20160712, 20160713, 20160714, 20160715, 20160718, 20160719, 20160720, 20160721, 20160722, 20160725, 20160726, 20160727, 20160728, 20160729, 20160801, 20160802, 20160803, 20160804, 20160805, 20160808, 20160809, 20160810, 20160811, 20160812, 20160815, 20160816, 20160817, 20160818, 20160819, 20160822, 20160823, 20160824, 20160825, 20160826, 20160829, 20160830, 20160831, 20160901, 20160902, 20160906, 20160907, 20160908, 20160909, 20160912, 20160913, 20160914, 20160915, 20160916, 20160919, 20160920, 20160921, 20160922, 20160923, 20160926, 20160927, 20160928, 20160929, 20160930, 20161003, 20161004, 20161005, 20161006, 20161007, 20161010, 20161011, 20161012, 20161013, 20161014, 20161017, 20161018, 20161019, 20161020, 20161021, 20161024, 20161025, 20161026, 20161027, 20161028, 20161031, 20161101, 20161102, 20161103, 20161104, 20161107, 20161108, 20161109, 20161110, 20161111, 20161114, 20161115, 20161116, 20161117, 20161118, 20161121, 20161122, 20161123, 20161125, 20161128, 20161129, 20161130, 20161201, 20161202, 20161205, 20161206, 20161207, 20161208, 20161209, 20161212, 20161213, 20161214, 20161215, 20161216, 20161219, 20161220, 20161221, 20161222, 20161223, 20161227, 20161228, 20161229, 20161230], \"y\": [-0.03664732117979673, -0.019899331528839256, -0.01392230526076969, -0.0118736156943925, -0.00792217538693684, 0.023409932046474992, -0.009601698005014423, -0.034521560073509185, -0.018855313762151358, -0.0002705513124361888, 0.002950787278327795, 0.013774940479983485, 0.015784536780801044, 0.010306949034296416, 0.019482357415813417, 0.02091350735678605, 0.013427287545796059, 0.02081546275283781, 0.04217868801020838, 0.07466090190442873, 0.061653297803678675, 0.061310020945403026, 0.058634897500792524, 0.05612531783013956, 0.05621618635447577, 0.06300618558520266, 0.06112095008567395, 0.06273367119924851, 0.05353188387159925, 0.0076254632988740426, 0.02436919399849128, 0.004617322451387126, 0.0005844457345628969, 0.008072993331063046, 0.0022731977274223626, -0.010252700367058406, -0.0004069867154726957, -0.010827768750323269, -0.023998873336810247, -0.014091208779683674, -0.007481759907977278, -0.008583403406051055, -0.0097622402143521, -0.004309216697581971, 0.004617590315884428, -0.00019758492645529884, 0.013059190513600568, 0.013310570932511794, 0.012571210743654023, 0.011752550144161015, 0.008044468995111933, 0.003614399116156894, 0.005959696186968284, 0.010351957451993113, 0.0062979528715901975, -0.0006123263098821129, -0.010250003433181068, 0.005444230350134993, 0.020213852262288497, 0.021941470198699426, 0.011138532444623985, 0.010421441746501704, 0.007816435734625655, 0.002539657740426486, -0.004145533837101751, 0.0013520751735404367, 0.002970555233133109, -0.0037624679137780244, -0.008762057950193929, -0.0077759362024162285, 0.011231408750440215, 0.016031709073326076, 0.008268116350115252, 0.00930742999522772, 0.01274274287316155, 0.018257011703824474, 0.02676047991456013, 0.032418726762741934, 0.0218018849816873, 0.03430663247363345, 0.03061536551596765, 0.0187172453870019, 0.020311463690671657, 0.027676883699476656, 0.020401410190139482, -0.003444153643420368, -0.01323965183726717, -0.023208969596910985, -0.008287088378489856, 0.0065811034748752, -0.021286574582731217, -0.02429108790378256, -0.03469961030549545, -0.0747294414563592, -0.06320242079788617, -0.0514335225041429, -0.03181711088257639, 0.0045964475507713175, 0.01426157475401246, -0.02718652973298458, -0.023094122652412195, -0.02396482943578867, -0.03926923395696776, -0.005662724179273257, 0.014143224968360018, 0.021507874407425676, 0.0043330469056092145, -0.030104948505228112, -0.02574631992173887, -0.0021081184932341627, -0.01323866489606881, -0.0017790902665010527, 0.016501078274096144, 0.0283668919185708, 0.02443177800142847, 0.028477645993465407, 0.046298265439075566, 0.0544558035865159, 0.031291393205312074, 0.016594761522891008, -7.821576366529026e-05, 0.0005890063415195588, 0.0001443790594486856, -0.002274513643228138, -0.005424926019384978, 2.756167859737507e-05, -0.015378615787593943], \"type\": \"scatter\", \"uid\": \"4150dc66-314b-467f-b3ef-2e734e063df0\"}], {\"title\": \"returnsOpenPrevMktres10: GOOG.O vs GOOGL.O\", \"xaxis\": {\"showticklabels\": false, \"title\": \"Date\"}, \"yaxis\": {\"title\": \"USD\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"198bee6c-ac3a-417e-9a02-6eec495b72cd\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def goscatter(df, col):\n",
    "    return go.Scatter(x=df['time'].values, y=df[col].values)\n",
    "\n",
    "# trace 0: blue, trace 1: orange\n",
    "#data = [goscatter(eg1_df, 'returnsOpenPrevMktres10'), goscatter(eg1_df, 'returnsOpenNextMktres10')]\n",
    "data = [goscatter(eg1_df, 'returnsOpenPrevMktres10'), goscatter(eg2_df, 'returnsOpenPrevMktres10')]\n",
    "layout = go.Layout(title=\"returnsOpenPrevMktres10: GOOG.O vs GOOGL.O\",\n",
    "                   xaxis=dict(title='Date', showticklabels=False), yaxis=dict(title='USD'))\n",
    "py.iplot(go.Figure(data=data, layout=layout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8b5b818ef560c2b28e1a942e0cea05ffef4917a9"
   },
   "source": [
    "# Training Data - News\n",
    "Show summary of `news_train_df`\n",
    "\n",
    "Change 'time' to an integer YYYYMMDD. (Integer not string for flexability)<br>\n",
    "\n",
    "*Note on columns:*\n",
    "There can be several articles on the same day for a specific asset. Lumping them all together so that they can be treated as one is going to be tricky since an alert (`urgency == 1`) is probably more weighty than an article (`urgency == 3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "56e59b8b55dc4b6de7d3e2987671fec4a6cb84f6"
   },
   "outputs": [],
   "source": [
    "summary(news_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "bd8d73cdf8edc82297aac5d3c016c23098ce5f90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted news time to integer YYYYMMDD (and removed time)\n",
      "Getting news samples from 20100101 to 20161230\n"
     ]
    }
   ],
   "source": [
    "if use_news:\n",
    "    if news_train_df['time'].dtype != 'int':\n",
    "        news_train_df['time'] = news_train_df['time'].dt.strftime(date_format='%Y%m%d').astype(int).values\n",
    "        print (\"Converted news time to integer YYYYMMDD (and removed time)\")\n",
    "\n",
    "    print (\"Getting news samples from\",trainfrom,\"to\",trainto)\n",
    "    news_sample = news_train_df.loc[get_dates(news_train_df, datefrom=trainfrom, dateto=trainto)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c57cb298251043bf11aa35a4a544ce1f107ae17"
   },
   "source": [
    "**Example finding news for GOOG.O**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7ca9bd6defad3dc315f324b0ea7f60e3c591f2d"
   },
   "outputs": [],
   "source": [
    "# For expressions you can set: flags=re.IGNORECASE, regex=True\n",
    "def get_news(df, cols, acol, asset, flags=0, regex=False, datefrom=None, dateto=None):\n",
    "    search_asset = ((df[acol].str.contains(asset, flags=flags, regex=regex)) &\n",
    "                    get_dates(df, datefrom=datefrom, dateto=dateto))\n",
    "    return df[cols].loc[search_asset]\n",
    "    \n",
    "#get_news(news_train_df, news_train_df.columns, 'assetCodes', 'GOOG.O', datefrom=20160630, dateto=20171230).head(6)\n",
    "goog_one_day_eg = get_news(news_train_df, news_train_df.columns, 'assetCodes', 'GOOG.O', datefrom=20160630)\n",
    "print (goog_one_day_eg.shape[0],\"GOOG.O news items for one day example. Below are the first 3...\")\n",
    "goog_one_day_eg.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dab7e7f7a9358b320e13abd302e177799932c698"
   },
   "source": [
    "# Training Data - Merging Market with News\n",
    "Define the functions we'll use to manipulate the market and news dataframes.\n",
    "\n",
    "Define the dates we are happy to use.<br>\n",
    "*NOTE: including 2007-2009 gives strange results when generating comparative \"all zero precictions\". I get an RMSE of 9.4 so I assume there are some spikes in the data that affect affect this average). Therefore don't use this period.*\n",
    "\n",
    "Get market samples using whatever columns we think are most important.\n",
    "\n",
    "Define the market and news columns which get the best result:<br>\n",
    "* `asset_predictors`: those columns I want in the market data\n",
    "* `select_news_cols` is used to select data initially from `news_train_df`\n",
    "* `append_news_cols` is asset_predictors with keys (time and assetCode (singular)) for merging news and market data\n",
    "\n",
    "Get news samples. News is expanded there is only one asset per row.\n",
    "\n",
    "Split and consolidate news into 8 manageable and meaningful \"news item\" chunks for each day and asset. The chunks are:\n",
    "* urgency = 1 and firstMentionSentence = 0\n",
    "* urgency = 1 and firstMentionSentence = 1\n",
    "* urgency = 1 and firstMentionSentence = 2\n",
    "* urgency = 1 and firstMentionSentence = >=3\n",
    "* urgency = 3 and firstMentionSentence = 0\n",
    "* urgency = 3 and firstMentionSentence = 1\n",
    "* urgency = 3 and firstMentionSentence = 2\n",
    "* urgency = 3 and firstMentionSentence = >=3<br>\n",
    "*NOTE: the sentiment values are added together - do I want to squash the resultant value (eg. with sigmoid)?*<br>\n",
    "*NOTE: what do I do with marketCommentary?*\n",
    "\n",
    "Then merge the news chunks with the market data. The Market sample will have 58 columns 10 + (8 x 6).\n",
    "\n",
    "Display part of the market sample which has news for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61680ce83f283914ea69bf2abc8c652d74e8270a"
   },
   "outputs": [],
   "source": [
    "# remove all non-(alphanum|dots|commas), then split using the comma and flatten list-of-lists\n",
    "def one_asset_per_row(ser):\n",
    "    return list(chain.from_iterable(ser.str.replace('[^\\w\\.\\,]','').str.split(',')))\n",
    "\n",
    "def get_asset_count_arr(df):\n",
    "    return df['assetCodes'].str.split(',').map(len)\n",
    "\n",
    "def expand_assetCodes(df, cols):\n",
    "    assetCodes = one_asset_per_row(df['assetCodes'])  # list of assets\n",
    "    asset_count_arr = get_asset_count_arr(df)         # how above assets are grouped\n",
    "    newdf = pd.DataFrame(columns=cols)\n",
    "    for col in cols:\n",
    "        if (col == 'assetCode'):\n",
    "            newdf['assetCode'] = assetCodes\n",
    "        else:\n",
    "            newdf[col] = np.repeat(df[col].values, asset_count_arr)\n",
    "    return newdf\n",
    "\n",
    "def get_news_search(df, urgency, firstMentionSentence):\n",
    "    if (firstMentionSentence == 'N'):\n",
    "        return ((df['urgency'] == urgency) &\n",
    "                (df['firstMentionSentence'] >= 3))\n",
    "    else:\n",
    "        return ((df['urgency'] == urgency) &\n",
    "                (df['firstMentionSentence'] == firstMentionSentence))\n",
    "\n",
    "def get_news_sample(df, search, keys):\n",
    "    return df.loc[search].groupby(keys, as_index=False, sort=False).sum(numeric_only=True)\n",
    "\n",
    "def merge_mn(marketdf, newsdf, keys, how, suffixes):\n",
    "    return pd.merge(marketdf, newsdf, on=keys, how=how, suffixes=suffixes)\n",
    "\n",
    "# Append relevant newsdf to marketsdf\n",
    "def OLD_split_merge_news(marketdf, newsdf, keys):\n",
    "    sum_newsdf = newsdf.groupby(keys, as_index=False, sort=False).sum(numeric_only=True)\n",
    "    return merge_mn(marketdf, sum_newsdf, keys, 'left', ['',''])\n",
    "\n",
    "# Append relevant newsdf to marketsdf\n",
    "def split_merge_news(marketdf, newsdf, keys):\n",
    "    search_alert0 = get_news_search(newsdf, 1, 0)\n",
    "    search_alert1 = get_news_search(newsdf, 1, 1)\n",
    "    search_alert2 = get_news_search(newsdf, 1, 2)\n",
    "    search_alertN = get_news_search(newsdf, 1, 'N')\n",
    "    search_article0 = get_news_search(newsdf, 3, 0)\n",
    "    search_article1 = get_news_search(newsdf, 3, 0)\n",
    "    search_article2 = get_news_search(newsdf, 3, 0)\n",
    "    search_articleN = get_news_search(newsdf, 3, 'N')\n",
    "    alert0df = get_news_sample(newsdf, search_alert0, keys)\n",
    "    alert1df = get_news_sample(newsdf, search_alert1, keys)\n",
    "    alert2df = get_news_sample(newsdf, search_alert2, keys)\n",
    "    alertNdf = get_news_sample(newsdf, search_alertN, keys)\n",
    "    article0df = get_news_sample(newsdf, search_article0, keys)\n",
    "    article1df = get_news_sample(newsdf, search_article1, keys)\n",
    "    article2df = get_news_sample(newsdf, search_article2, keys)\n",
    "    articleNdf = get_news_sample(newsdf, search_articleN, keys)\n",
    "    marketdf = merge_mn(marketdf, alert0df, keys, 'left', ['',''])\n",
    "    marketdf = merge_mn(marketdf, alert1df, keys, 'left', ['_alert0','_alert1'])\n",
    "    marketdf = merge_mn(marketdf, alert2df, keys, 'left', ['',''])\n",
    "    marketdf = merge_mn(marketdf, alertNdf, keys, 'left', ['_alert2','_alertN'])\n",
    "    marketdf = merge_mn(marketdf, article0df, keys, 'left', ['',''])\n",
    "    marketdf = merge_mn(marketdf, article1df, keys, 'left', ['_article0','_article1'])\n",
    "    marketdf = merge_mn(marketdf, article2df, keys, 'left', ['',''])\n",
    "    marketdf = merge_mn(marketdf, articleNdf, keys, 'left', ['_article2','_articleN'])\n",
    "    return marketdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e698647f248a447b0ece90e01e6b5a3b2a689d60"
   },
   "source": [
    "**For re-runs start here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18db50c5fcda64a377bbff3c2c3b329baa197017"
   },
   "outputs": [],
   "source": [
    "# for re-runs since memory is a bit tight\n",
    "try:\n",
    "    sys.getsizeof(trainx)\n",
    "    del market_sample\n",
    "    del news_sample\n",
    "    del trainx\n",
    "    del validx\n",
    "    gc.collect()\n",
    "    print (\"Memory freed\")\n",
    "except:\n",
    "    print (\"First run - no memory can be freed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0cd1ca7b766b9f3401ed13f6c17a32b793bf222"
   },
   "outputs": [],
   "source": [
    "# MARKET: drop: 'time', 'assetCode', 'assetName', 'returnsOpenNextMktres10'\n",
    "market_cols = ['time', 'assetCode', 'assetName', 'volume',\n",
    "               'returnsOpenPrevMktres1', 'returnsOpenPrevMktres10',\n",
    "               'returnsClosePrevMktres1', 'returnsClosePrevMktres10',\n",
    "               'returnsOpenNextMktres10']\n",
    "# MARKET: -or- not drop, that is the question\n",
    "#market_cols = market_train_df.columns\n",
    "print (\"market_cols:\", market_cols)\n",
    "print (\"\")\n",
    "market_sample = market_sample[market_cols]\n",
    "print (\"Market train shape is \", market_train_df.shape)\n",
    "print (\"Market sample shape is\", market_sample.shape)\n",
    "\n",
    "if use_news:\n",
    "    # NEWS: asset_predictors are the news columns I want to in market data\n",
    "    # NEWS: select_news_cols is to select the information initially from news_train_df\n",
    "    # NEWS: append_news_cols is asset_predictors with keys (time and assetCode (singular)) for merging news with market data\n",
    "    #asset_predictors = ['urgency', 'marketCommentary', 'firstMentionSentence',\n",
    "    #                    'sentimentNegative', 'sentimentNeutral', 'sentimentPositive']\n",
    "    # NEWS: NOT APPENDED: 'time', 'headline', assetCode'\n",
    "    # NEWS: NOT APPENDED: 'time', 'sourceTimestamp', 'firstCreated', 'sourceId', 'assetName',\n",
    "    # NEWS: NOT APPENDED: 'takeSequence', 'provider', 'subjects', 'audiences', 'headlineTag',\n",
    "    asset_predictors = ['urgency', 'marketCommentary',\n",
    "       'sentenceCount', 'wordCount', 'firstMentionSentence', 'relevance', 'sentimentClass',\n",
    "       'sentimentNegative', 'sentimentNeutral', 'sentimentPositive']\n",
    "    #asset_predictors = ['urgency', 'bodySize', 'companyCount', 'marketCommentary',\n",
    "    #   'sentenceCount', 'wordCount', 'firstMentionSentence', 'relevance', 'sentimentClass',\n",
    "    #   'sentimentNegative', 'sentimentNeutral', 'sentimentPositive',\n",
    "    #   'sentimentWordCount', 'noveltyCount12H', 'noveltyCount24H',\n",
    "    #   'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H',\n",
    "    #   'volumeCounts24H', 'volumeCounts3D', 'volumeCounts5D', 'volumeCounts7D']\n",
    "    select_news_cols = ['time', 'headline', 'assetCodes'] + asset_predictors\n",
    "    append_news_cols = ['time', 'assetCode'] + asset_predictors   # NOTE: 'assetCode' will exist when this is used\n",
    "    print (\"select_news_cols:\", select_news_cols)\n",
    "    print (\"\")  \n",
    "    print (\"Expanding news:\")\n",
    "    news_sample = news_sample[select_news_cols]\n",
    "    print (\"News train shape is   \", news_train_df.shape)\n",
    "    print (\"News sample shape is  \", news_sample.shape)\n",
    "    news_sample = expand_assetCodes(news_sample, append_news_cols)\n",
    "    print (\"News expanded shape is\", news_sample.shape)\n",
    "\n",
    "    print (\"Merging news and market data\")\n",
    "    market_sample = split_merge_news(market_sample, news_sample, ['time','assetCode'])\n",
    "\n",
    "    print (\"Market plus News sample shape is\", market_sample.shape)\n",
    "    print (\"Market plus News sample - first 5 entries with at least one urgency>0 news item\")\n",
    "    market_sample.loc[market_sample['urgency_alert0'] > 0].head(5).T\n",
    "    #market_sample.loc[market_sample['urgency'] > 0].head(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd591dafeec9e1e041a1984f1f48f57c4f8be63f"
   },
   "outputs": [],
   "source": [
    "summary(market_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc4c30dc272407c73550b90a11ffebbc56282adc"
   },
   "source": [
    "# Training Data - Preparation\n",
    "Drop unused columns.\n",
    "\n",
    "Opportunity to sort the values, however, it's already sorted by time and assetCode and this seems to work better than assetCode then time.<br>\n",
    "Split into training and validation data.\n",
    "\n",
    "Save labels time, assetCode and assetName for checks later on.\n",
    "\n",
    "Encode the assetCode.\n",
    "\n",
    "Any strings dropped.\n",
    "\n",
    "Some checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7d070e43123685b0b92b72de4d9ea44af00e2b6"
   },
   "outputs": [],
   "source": [
    "def get_unused(df):\n",
    "    rows = df.shape[0]\n",
    "    ddf = df.isna().sum()\n",
    "    return list(ddf[ddf >= rows].index)\n",
    "\n",
    "def encode_col(df, col, uvalues):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(uvalues)\n",
    "    return le.transform(df[col].astype('str'))\n",
    "\n",
    "def split_data(df, sortkeys=None, test_size=0.1, shuffle=True):\n",
    "    tx, vx, ty, vy = train_test_split(df, df['returnsOpenNextMktres10'], test_size=test_size, shuffle=shuffle)\n",
    "    ty = ty.fillna(0).values\n",
    "    vy = vy.fillna(0).values\n",
    "    if (sortkeys!=None):\n",
    "        tx = tx.sort_values(by=sortkeys)\n",
    "        vx = vx.sort_values(by=sortkeys)\n",
    "    return tx, vx, ty, vy\n",
    "\n",
    "def convert_to_float(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "94cebc3ec2b29fc24a199d026ee528c845ac79aa"
   },
   "outputs": [],
   "source": [
    "# Drop unused\n",
    "train_unused_cols = get_unused(market_sample)\n",
    "market_sample.drop(columns=train_unused_cols, inplace=True)\n",
    "print (\"Dropped these unused columns from market data:\", train_unused_cols)\n",
    "print (\"\")\n",
    "rows_before = market_sample.shape[0]\n",
    "market_sample.dropna(how='any', inplace=True)\n",
    "rows_after = market_sample.shape[0]\n",
    "print (\"Dropped {:d} rows from market data due to NaN value\".format(rows_before-rows_after))\n",
    "print (\"\")\n",
    "\n",
    "print (\"Splitting the data into trainx/y and validx/y\")\n",
    "#sortkeys = ['time','assetCode']\n",
    "#sortkeys = ['assetCode', 'time']\n",
    "sortkeys = None\n",
    "trainx, validx, trainy, validy = split_data(market_sample.copy(), sortkeys=sortkeys, test_size=0.1, shuffle=False)\n",
    "_time = validx['time'].values   # HACK for one of the NeuralNets trying to use lgb.get_field() \n",
    "\n",
    "print (\"Saving labels for checking: time, assetCode and assetName\")\n",
    "trainx_label = trainx[['time', 'assetCode', 'assetName']]\n",
    "validx_label = validx[['time', 'assetCode', 'assetName']]\n",
    "\n",
    "print (\"No column needs encoding\")\n",
    "#print (\"Encode assetCode\")\n",
    "#unique_assetCodes = market_sample['assetCode'].astype(str).unique()\n",
    "#trainx['assetCode'] = encode_col(trainx, 'assetCode', unique_assetCodes)\n",
    "#validx['assetCode'] = encode_col(validx, 'assetCode', unique_assetCodes)\n",
    "\n",
    "# set \"string\" columns to remove based on encoding (above)\n",
    "train_str_cols = ['time', 'assetCode', 'assetName']\n",
    "#train_str_cols = ['assetName']\n",
    "print (\"Dropped these columns from trainx:\", train_str_cols + ['returnsOpenNextMktres10'])\n",
    "trainx.drop(columns=train_str_cols + ['returnsOpenNextMktres10'], inplace=True)\n",
    "validx.drop(columns=train_str_cols + ['returnsOpenNextMktres10'], inplace=True)\n",
    "\n",
    "print (\"Converting everything to float\")\n",
    "trainx = convert_to_float(trainx)\n",
    "validx = convert_to_float(validx)\n",
    "\n",
    "# Checks\n",
    "assert set(trainx.columns) == set(validx.columns)\n",
    "print (\"trainx shape:\", trainx.shape, \"trainy (numpy) shape:\", trainy.shape)\n",
    "print (\"validx shape:\", validx.shape, \"validy (numpy) shape:\", validy.shape)\n",
    "summary(validx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c9185de6b23a38682cf499b78cb5ab2cc3b8a076"
   },
   "source": [
    "# Neural Net\n",
    "So far, the predictions are not much better than using all zeros for predictions. Definitely room for improvement.<br>\n",
    "When I get better results I can work on converting the y values into confidence values between -1 and 1.\n",
    "\n",
    "Notes:<br>\n",
    "Score is calculated as follows:<br>\n",
    "1. x_timearray = Sum (sigma) of one day's assets (confidence * Mktres10 * universe)<br>\n",
    "2. score = mean(x_timearray) / stddev(x_timearray)\n",
    "*NOTE on universe in training:<br>\n",
    "Including the universe does not make sense since it is not in the test data. The more universe==0 assets there are in a day's trading the larger the affect will be on the means and standard deviations. Is this not training for something that will never appear in test?*\n",
    "\n",
    "Tried:<br>\n",
    "* Changing the date: I get slightly better results with 1/1/2010 - 30/12/2016 (ie. ignore 2007-2009)\n",
    "* Encoding time and assetCode: not much difference - left them out\n",
    "* More market cols: not much difference - kept only `volume` and `returnsOpenPrevMktres10`\n",
    "* More news cols: \n",
    "\n",
    "Calculations are:<br>\n",
    "* RMSE trainy - predictions of trainy (to see how \"trained\" the model is; with no consideration for overfitting)\n",
    "* RMSE trainy - predictions of all zero\n",
    "* RMSE trainy - predictions with are random\n",
    "* **RMSE validy - predictions of validy (the best indicator a good model for this kernel)**\n",
    "* RMSE validy - predictions of all zero\n",
    "* RMSE validy - predictions which are random\n",
    "* all the above repeated using MAE (Mean of Absolute Error) for comparison\n",
    "\n",
    "Prediction scores for: **validy - predictions of validy**\n",
    "* RMSE: `0.5812` USING: all random\n",
    "* RMSE: `0.0658` USING: all zeros\n",
    "* RMSE: `0.0626` USING: sort:time,asset; date:2010-end; market cols: bare minimum\n",
    "\n",
    "*NOTE: sort:time,asset and sort:None are the same*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b6a4cd9fba76ac1e094657609f33e9b4dccb86f"
   },
   "outputs": [],
   "source": [
    "def train_nn(trainx, trainy, validx, validy):\n",
    "    params = {\n",
    "        \"objective\"               : \"regression_l1\",\n",
    "        \"metric\"                  : \"None\", \n",
    "        \"num_leaves\"              : 15,\n",
    "        \"learning_rate\"           : 0.1,\n",
    "        \"max_depth\"               : -1,\n",
    "        \"min_data_in_leaf\"        : 20,\n",
    "        \"min_sum_hessian_in_leaf\" : 1e-3,\n",
    "        \"bagging_fraction\"        : 0.5,\n",
    "        \"feature_fraction\"        : 1.0,\n",
    "        \"bagging_freq\"            : 2,\n",
    "        \"lambda_l1\"               : 0,\n",
    "        \"lambda_l2\"               : 0\n",
    "    }\n",
    "    def score(_predvy, _validlgb):\n",
    "        _validy = _validlgb.get_label()\n",
    "        #x = pd.DataFrame({'sigma': (_predvy * _validy * _universe)}).groupby(_time).sum()\n",
    "        x = pd.DataFrame({'sigma': (_predvy * _validy)}).groupby(_time).sum()\n",
    "        return 'sigma_score', (x['sigma'].mean() / x['sigma'].std()), True\n",
    "\n",
    "    evals_result = {}\n",
    "    #_time     = validx['time'].values      # because _validlgb.get_field() does not work\n",
    "    #_universe = validx['universe'].values  # because _validlgb.get_field() does not work\n",
    "    trainlgb = lgb.Dataset(trainx, label=trainy)\n",
    "    validlgb = lgb.Dataset(validx, label=validy)\n",
    "    return lgb.train(params, trainlgb, num_boost_round=500, valid_sets=(validlgb), valid_names=('valid'), verbose_eval=25,\n",
    "               early_stopping_rounds=25, feval=score, evals_result=evals_result)\n",
    "    #df_result = pd.DataFrame(evals_result['valid'])\n",
    "\n",
    "nn = train_nn(trainx, trainy, validx, validy)\n",
    "predvy = nn.predict(validx, num_iteration=nn.best_iteration)\n",
    "predty = nn.predict(trainx, num_iteration=nn.best_iteration)\n",
    "\n",
    "lgb.plot_importance(nn, figsize=(10,10), height=0.8, grid=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e855da8a5567827b1e5fdff513a3fdfc03c1e57"
   },
   "outputs": [],
   "source": [
    "# Area Under Curve (AUC)\n",
    "# Prediction score of: 0.0, 0.5 and 1.0 are perfect opposite, not better than chance and perfect scores respectively\n",
    "def train_nn(trainx, trainy, validx, validy):\n",
    "    params = {\n",
    "        'objective'          : 'binary',\n",
    "        'metric'             : 'auc',\n",
    "        'learning_rate'      : 0.1,\n",
    "        'max_depth'          : 12,\n",
    "        'boosting'           : 'gbdt',\n",
    "        'is_training_metric' : True,\n",
    "        'seed'               : 42\n",
    "    }\n",
    "    trainlgb = lgb.Dataset(trainx, label=trainy)\n",
    "    validlgb = lgb.Dataset(validx, label=validy)\n",
    "    return lgb.train(params, trainlgb, num_boost_round=2000, valid_sets=[validlgb], early_stopping_rounds=100, verbose_eval=100)\n",
    "\n",
    "nn = train_nn(trainx, trainy, validx, validy)\n",
    "predvy = nn.predict(validx, num_iteration=nn.best_iteration)\n",
    "predty = nn.predict(trainx, num_iteration=nn.best_iteration)\n",
    "\n",
    "lgb.plot_importance(nn, figsize=(10,10), height=0.8, grid=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16b0e220707a67c301ee909c7a3e3d90b778a8bf"
   },
   "outputs": [],
   "source": [
    "def train_nn(trainx, trainy, validx, validy):\n",
    "    params = {\n",
    "        \"objective\"         : \"regression\",\n",
    "        \"metric\"            : \"rmse\",\n",
    "        \"num_leaves\"        : 30,\n",
    "        \"min_child_samples\" : 100,\n",
    "        \"learning_rate\"     : 0.1,\n",
    "        \"bagging_fraction\"  : 0.7,\n",
    "        \"feature_fraction\"  : 0.5,\n",
    "        \"bagging_freq\"      : 5,\n",
    "        \"bagging_seed\"      : 2018,\n",
    "        \"verbosity\"         : -1\n",
    "    }\n",
    "    trainlgb = lgb.Dataset(trainx, label=trainy)\n",
    "    validlgb = lgb.Dataset(validx, label=validy)\n",
    "    return lgb.train(params, trainlgb, num_boost_round=500, valid_sets=[validlgb], early_stopping_rounds=100, verbose_eval=100)\n",
    "\n",
    "nn = train_nn(trainx, trainy, validx, validy)\n",
    "predvy = nn.predict(validx, num_iteration=nn.best_iteration)\n",
    "predty = nn.predict(trainx, num_iteration=nn.best_iteration)\n",
    "\n",
    "lgb.plot_importance(nn, figsize=(10,10), height=0.8, grid=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55be6ac5bfee7dc4ba75d1ab6baafc9c0a2ff175"
   },
   "outputs": [],
   "source": [
    "def get_y_predy(labeldf, y, predy):\n",
    "    return pd.DataFrame({'time':                      labeldf['time'].values,\n",
    "                         'assetCode':                 labeldf['assetCode'].values,\n",
    "                         'returnsOpenNextMktres10':   y,\n",
    "                         'predictedOpenNextMktres10': predy,\n",
    "                         'allZeros':                  [0] * len(predy),\n",
    "                         'randomPreds':               (2.0 * np.random.rand(len(predy)) - 1.0) / 10,\n",
    "                         })\n",
    "\n",
    "#RMSE (Root Mean Squared Error): 1. Square all Errors (y-predy); 2. take the Mean; 3. then the Root\n",
    "def rmse(df, col1, col2):\n",
    "    #return np.sqrt(np.mean((df[col1].values - df[col2].values) ** 2))\n",
    "    return np.sqrt(metrics.mean_squared_error(df[col1].values, df[col2].values))\n",
    "\n",
    "#MAE (Mean Absolute Error): 1. abs(y-predy); 2. take the mean\n",
    "def mae(df, col1, col2):\n",
    "    #return np.mean(abs(df[col1].values - df[col2].values))\n",
    "    return metrics.mean_absolute_error(df[col1].values, df[col2].values)\n",
    "\n",
    "def show_preds(traindf, validdf, name, col):\n",
    "    print (\"trainy - {:s} = RMSE:{:1.4f} (MAE:{:1.4f})\".format(name,\n",
    "        rmse(traindf, 'returnsOpenNextMktres10', col),\n",
    "        mae( traindf, 'returnsOpenNextMktres10', col)))\n",
    "    print (\"validy - {:s} = RMSE:{:1.4f} (MAE:{:1.4f})\".format(name,\n",
    "        rmse(validdf, 'returnsOpenNextMktres10', col),\n",
    "        mae( validdf, 'returnsOpenNextMktres10', col)))\n",
    "\n",
    "trainpreds = get_y_predy(trainx_label, trainy, predty)\n",
    "validpreds = get_y_predy(validx_label, validy, predvy)\n",
    "show_preds(trainpreds, validpreds, 'random', 'randomPreds')\n",
    "show_preds(trainpreds, validpreds, 'all zeros', 'allZeros')\n",
    "show_preds(trainpreds, validpreds, 'pred validy', 'predictedOpenNextMktres10')\n",
    "print (\"First 10 lines of validation prediction:\")\n",
    "validpreds.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "840aa03b49d675953f080e4069f79f435282bb43"
   },
   "source": [
    "# Test Data\n",
    "Two Sigma has written access routines forcing you to iterate through the test data.<br>\n",
    "Above we initialised: `test_split_df = env.get_prediction_days()`<br>\n",
    "We iterate one day at a time using: `(market_test_df, news_test_df, prediction_df) = next(test_split_df)`<br>\n",
    ". for each `prediction_df.assetCode` we set: `prediction_df.confidenceValue` *(those are the only two values)*<br>\n",
    ". and then apply: `env.predict(prediction_df)`<br>\n",
    "We finish with: `env.write_submission_file()`<br>\n",
    "\n",
    "The iterations are split into three chunks in this kernel to retain flexibility whilst testing `test_split_df`:\n",
    "* First prediction, where I can scrutinise the first day's test data (and define make_random_predictions)\n",
    "* The remaining predictions\n",
    "* Last day's test data and prediction can be scrutinised after next() returns 'no more data' error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25bf79f40c2e5cd86f6970436b08e5e41482ea42"
   },
   "outputs": [],
   "source": [
    "def make_predictions(market_test_df, news_test_df, predictions_df):\n",
    "    market_test_df['time'] = market_test_df['time'].dt.strftime(date_format='%Y-%m-%d').values\n",
    "    news_test_df['time'] = news_test_df['time'].dt.strftime(date_format='%Y-%m-%d').values\n",
    "    news_test_df = expand_assetCodes(news_test_df[select_news_cols], select_news_cols)\n",
    "    market_test_df = split_merge_news(market_test_df, news_test_df, ['time','assetCode'])\n",
    "    market_test_df.drop(columns=train_unused_cols, inplace=True)\n",
    "    market_test_df.drop(columns=train_str_cols, inplace=True)\n",
    "    market_test_df = convert_to_float(market_test_df)\n",
    "    predictions_df['confidenceValue'] = nn.predict(market_test_df, num_iteration=nn.best_iteration)    \n",
    "    # RANDOM: predictions_df['confidenceValue'] = 2.0 * np.random.rand(len(predictions_df)) - 1.0\n",
    "    # ZEROS:  predictions_df['confidenceValue'] = [0] * len(predictions_df)\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "724c38149860c8e9058474ac9045c2301e8a20da"
   },
   "outputs": [],
   "source": [
    "test_split_df = env.get_prediction_days()\n",
    "    \n",
    "print (\"day1: first day's test data\")\n",
    "(market_test_df, news_test_df, predictions_template_df) = next(test_split_df)\n",
    "print (\"day1: market shape (rows=assets)\", market_test_df.shape)\n",
    "print (\"day1: news info shape (rows=newsinfo)\", news_test_df.shape)\n",
    "print (\"day1: pred template shape (cols=assets)\", predictions_template_df.shape)\n",
    "market_start_date = market_test_df['time'].head(1)[0]\n",
    "news_start_date = news_test_df['time'].head(1)[0]\n",
    "\n",
    "predictions_df = make_predictions(market_test_df, news_test_df, predictions_template_df)\n",
    "env.predict(predictions_df)\n",
    "predications_made = 1\n",
    "print (\"day1: actual predictions shape\", predictions_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "496457cdbb79f4f6f5a0cc73e7bcb0421e99a875"
   },
   "outputs": [],
   "source": [
    "print (\"Doing remaining predictions...\")\n",
    "while True:\n",
    "    try:\n",
    "        (market_test_df, news_test_df, predictions_template_df) = next(test_split_df)\n",
    "        market_end_date = market_test_df['time'].tail(1)[0]\n",
    "        news_end_date = news_test_df['time'].tail(1)[0]\n",
    "    except:\n",
    "        break\n",
    "    predictions_df = make_predictions(market_test_df, news_test_df, predictions_template_df)\n",
    "    env.predict(predictions_df)\n",
    "    predications_made = predications_made + 1\n",
    "print (\"Total\",predications_made,\"predictions of test made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17bf3eae3a0279656afbe34de703bf6f3dc55179"
   },
   "outputs": [],
   "source": [
    "print (\"market test dates:\",market_start_date,\"to\",market_end_date)\n",
    "print (\"news test dates:\",news_start_date,\"to\",news_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84209bbe6e9fb561e4e129813b2f48298d50bb3e"
   },
   "source": [
    "# Submission\n",
    "The file submission.csv will be written to the local directory when you **Commit** your kernel. Check the kernel output outside of the editor and when satisfied press the **Output** tab which will show a **Submit for Competition** button. This is the kernel that will be used for stage two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c8ed34ffb2c47c6e124530ec798c0b4eb01ddd5"
   },
   "outputs": [],
   "source": [
    "env.write_submission_file()\n",
    "print([filename for filename in os.listdir('.') if '.csv' in filename])\n",
    "!head ../working/submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2e3a267ea3149403c49ff59515a1a669ca2d1f9f"
   },
   "source": [
    "# Final word regarding the need to restart the kernel\n",
    "It has been said that the method `make_env` plus iterating through `get_prediction_days` is used to combat cheating, but since the winner will have to make successful predictions about real 2019 data I'm not sure how using any method the programmer desires will give them the upper hand. Surely, if there's a chance that a machine learning programmer can predict future stock prices with great accuracy then why not give them all the help they need?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
